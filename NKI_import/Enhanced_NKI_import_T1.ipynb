{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3]\n",
      "('/ab/test/this', '/gh/asdf/this')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'dd' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-d34093752ada>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'd'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dd'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: 'dd' is not in list"
     ]
    }
   ],
   "source": [
    "# Here define data directory and path to metadata csv file\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "tmp=['A','B','C','A','C']\n",
    "e,indeces=np.unique(tmp, return_index=True)\n",
    "h=[]\n",
    "h.append('/ab/test/this')\n",
    "h.append('/cb/asdf/this')\n",
    "h.append('/bf/asdd/this')\n",
    "h.append('/gh/asdf/this')\n",
    "\n",
    "ind=[0,3]\n",
    "print ind\n",
    "print itemgetter(*ind)(h)\n",
    "\n",
    "j=['a','b','c','d']\n",
    "j.index('dd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of structural scans is: 942\n",
      "length of functional scans is: 903\n",
      "length of unique structural scans is: 938\n",
      "length of unique functional scans is: 891\n",
      "(871, 938)\n",
      "A00052183\n",
      "mmilham/long_child_483009/A00052183/418858611_V2/MPRAGE_SIEMENS_DEFACED_0003/co18991230_000000A00052183s003a1001.nii.gz\n",
      "A00040248\n",
      "mmilham/discoverysci_30001/A00040248/395755775_V2/MPRAGE_SIEMENS_DEFACED_0011/co18991230_000000A00040248s011a1001.nii.gz\n",
      "A00064323\n",
      "mmilham/discoverysci_30001/A00064323/466670035_VA/MPRAGE_SIEMENS_DEFACED_0003/co18991230_000000A00064323s003a1001.nii.gz\n",
      "A00044405\n",
      "mmilham/discoverysci_30001/A00044405/411163737_V2/MPRAGE_SIEMENS_DEFACED_0003/co18991230_000000unknowns003a1001.nii.gz\n",
      "A00053744\n",
      "mmilham/long_child_483009/A00053744/421546114_V2/MPRAGE_SIEMENS_DEFACED_0003/co18991230_000000A00053744s003a1001.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os\n",
    "from operator import itemgetter\n",
    "\n",
    "metadata_sheet='Table'\n",
    "data_path='/nfs/zorba/DOWNLOADED/Enhanced_NKI/data/nki/dicom/triotim/'\n",
    "# Below will capture all the structural and functional dicom folders (some are duplicates)\n",
    "#T1_glob_data = '*/*/A*/*_V*/MPRAGE*/co*nii.gz' # Grabs all \n",
    "#T1_glob_data = '*/*/A*/*_V{2,A,_ALG}/MPRAGE*/co*nii.gz' # Grabs all baseline\n",
    "T1_glob_data = '*/*/A*/*_V[2,A,_ALG]/MPRAGE*/co*nii.gz' # Grabs all baseline, later can add the repeat session\n",
    "func_glob_data = '*/*/A*/*_V[2,A,_ALG]/REST*/*.nii.gz' # Come back and incorporate\n",
    "os.chdir(data_path)\n",
    "T1_scans=sorted(glob.glob(T1_glob_data)) # Focus on T1 scans for now\n",
    "func_scans=sorted(glob.glob(func_glob_data))\n",
    "print \"length of structural scans is: \" + str(len(T1_scans))\n",
    "print \"length of functional scans is: \" + str(len(func_scans))\n",
    "# Now get only unique ids for structural scans\n",
    "tmp=[]\n",
    "for s in T1_scans:\n",
    "    tmp.append(s.split('/')[2])\n",
    "    \n",
    "T1_subject_ids,indeces=np.unique(tmp, return_index=True)\n",
    "# Now T1_scans list is only filled with unique values\n",
    "T1_scans=itemgetter(*indeces)(T1_scans)\n",
    "print \"length of unique structural scans is: \" + str(len(T1_scans))\n",
    "\n",
    "# Now get only unique ids for functional lores resting scans\n",
    "tmp=[]\n",
    "for s in func_scans:\n",
    "    tmp.append(s.split('/')[2])\n",
    "    \n",
    "func_subject_ids,indeces=np.unique(tmp, return_index=True)\n",
    "# Now T1_scans list is only filled with unique values\n",
    "func_scans=itemgetter(*indeces)(func_scans)\n",
    "print \"length of unique functional scans is: \" + str(len(func_scans))\n",
    "\n",
    "dict_scan = {}\n",
    "### Read and Parse XSL\n",
    "# metadata_file='/Users/haiyuancao/GitHub/xnat_import/scan-new/8100_IRI_20161115_2.csv'\n",
    "\n",
    "metadata_file_2 = '/nfs/zorba/Dropbox/NKI/8100_Demos_20170117.csv'\n",
    "df = pd.read_csv(metadata_file_2)\n",
    "#df['Anoymized ID'] = df['Anoymized ID'].apply(lambda x: unicode(x))\n",
    "#id_list = df['Anonymized ID'].values.tolist()\n",
    "df_2 = df.set_index('Anonymized ID')\n",
    "id_list = df_2.index.tolist()\n",
    "subject_dict = {}\n",
    "count=0\n",
    "\n",
    "for i in range(len(T1_subject_ids)):\n",
    "    item=T1_subject_ids[i] # Item is the subject ID \"i.e. A00053278\"\n",
    "    T1_path=T1_scans[i]\n",
    "    #print (item)\n",
    "    #print file_path\n",
    "    if item in id_list:\n",
    "        # Here go ahead and grab the subject's lores REST func_path too\n",
    "        try:\n",
    "            func_index = func_subject_ids.tolist().index(item)\n",
    "            func_path  = func_scans[func_index]\n",
    "        except: \n",
    "            func_path = []\n",
    "        #print id_list.index(item)\n",
    "        count += 1\n",
    "        df_index =id_list.index(item)\n",
    "        age = df_2.iloc[df_index]['DEM_001']\n",
    "        sex = df_2.iloc[df_index]['DEM_002']\n",
    "        \n",
    "        #print (age, sex)\n",
    "        subject_dict[item] = {'age': \"\", \"sex\": \"\", \"T1_path\":\"\", \"func_path\":\"\"}\n",
    "        subject_dict[item]['age'] = age\n",
    "        subject_dict[item]['sex'] = sex\n",
    "        subject_dict[item]['T1_path'] = T1_path\n",
    "        subject_dict[item]['func_path'] = func_path\n",
    "       \n",
    "print (count, len(T1_subject_ids))\n",
    "\n",
    "for key, value in subject_dict.items()[0:5]:\n",
    "    print key  \n",
    "    print value[\"T1_path\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A00052183\n",
      "mmilham/long_child_483009/A00052183/418858611_V2/MPRAGE_SIEMENS_DEFACED_0003/co18991230_000000A00052183s003a1001.nii.gz\n",
      "Now insert subject with key: A00052183\n",
      "NKI_A00052183_MR1\n",
      "A00040248\n",
      "mmilham/discoverysci_30001/A00040248/395755775_V2/MPRAGE_SIEMENS_DEFACED_0011/co18991230_000000A00040248s011a1001.nii.gz\n",
      "Now insert subject with key: A00040248\n",
      "NKI_A00040248_MR1\n",
      "A00064323\n",
      "mmilham/discoverysci_30001/A00064323/466670035_VA/MPRAGE_SIEMENS_DEFACED_0003/co18991230_000000A00064323s003a1001.nii.gz\n",
      "Now insert subject with key: A00064323\n",
      "NKI_A00064323_MR1\n",
      "A00044405\n",
      "mmilham/discoverysci_30001/A00044405/411163737_V2/MPRAGE_SIEMENS_DEFACED_0003/co18991230_000000unknowns003a1001.nii.gz\n",
      "Now insert subject with key: A00044405\n",
      "NKI_A00044405_MR1\n",
      "A00053744\n",
      "mmilham/long_child_483009/A00053744/421546114_V2/MPRAGE_SIEMENS_DEFACED_0003/co18991230_000000A00053744s003a1001.nii.gz\n",
      "Now insert subject with key: A00053744\n",
      "NKI_A00053744_MR1\n",
      "A00043758\n",
      "mmilham/discoverysci_30001/A00043758/408377626_V2/MPRAGE_SIEMENS_DEFACED_0003/co18991230_000000unknowns003a1001.nii.gz\n",
      "Now insert subject with key: A00043758\n",
      "NKI_A00043758_MR1\n",
      "A00066735\n",
      "mmilham/discoverysci_30001/A00066735/473679890_VA/MPRAGE_SIEMENS_DEFACED_0003/co18991230_000000A00066735s003a1001.nii.gz\n",
      "Now insert subject with key: A00066735\n",
      "NKI_A00066735_MR1\n",
      "A00061021\n",
      "mmilham/discoverysci_30001/A00061021/453909824_V2/MPRAGE_SIEMENS_DEFACED_0003/co18991230_000000A00061021s003a1001.nii.gz\n",
      "Now insert subject with key: A00061021\n",
      "NKI_A00061021_MR1\n",
      "A00039075\n",
      "mmilham/discoverysci_30001/A00039075/387498575_V2/MPRAGE_SIEMENS_DEFACED_0003/co18991230_000000A00039075s003a1001.nii.gz\n",
      "Now insert subject with key: A00039075\n",
      "NKI_A00039075_MR1\n",
      "A00039074\n",
      "mmilham/discoverysci_30001/A00039074/387306275_V2/MPRAGE_SIEMENS_DEFACED_0005/co18991230_000000A00039074s005a1001.nii.gz\n",
      "Now insert subject with key: A00039074\n",
      "NKI_A00039074_MR1\n"
     ]
    }
   ],
   "source": [
    "import pyxnat\n",
    "import os\n",
    "delete_previous_scans = 0\n",
    "insert_scans = 1\n",
    "\n",
    "# Set project name\n",
    "project_name=\"NKI\"\n",
    "\n",
    "# connect to XNAT instance\n",
    "xnat=pyxnat.Interface(config='/home/spantazatos/xnat_sp.cfg')\n",
    "\n",
    "# Create the project in XNAT\n",
    "# Create project object\n",
    "project=xnat.select.project(project_name)\n",
    "\n",
    "# First check if it already exists\n",
    "if not project.exists():\n",
    "    project.insert()\n",
    "    \n",
    "for key, value in subject_dict.items():\n",
    "    print key\n",
    "    print value[\"T1_path\"]\n",
    "    \n",
    "    # Insert subject if not already there\n",
    "    print (\"Now insert subject with key: \" + key)\n",
    "    subject = project.subject(key)\n",
    "    if not subject.exists():\n",
    "        subject.insert()\n",
    "    \n",
    "    # Since this is baseline just do MR1 for now\n",
    "    session_label = \"%s_%s_MR1\" % (project_name,key)\n",
    "    print session_label\n",
    "    \n",
    "    experiment=subject.experiment(session_label) #.create(experiments='xnat:mrSessionData')\n",
    "   \n",
    "    # Create experiment object, insert if it doesn't already exst\n",
    "    if not experiment.exists():\n",
    "        experiment.create() # By default it will make an xnat:mrSessionData experiment which is what we need\n",
    "    \n",
    "    # Now insert subject-level attributes (i.e. SEX) and experiment-level attributes (i.e. AGE)\n",
    "    user_age = int(value['age'])\n",
    "    if value['sex'] == 1:\n",
    "        user_sex = 'Male'\n",
    "    else:\n",
    "        user_sex = 'Female'\n",
    "    \n",
    "#     sex = 'Male'\n",
    "#     weight = str(100)\n",
    "#     height = str(100)\n",
    "    \n",
    "    subject.attrs.set('xnat:subjectData/demographics[@xsi:type=xnat:demographicData]/gender', user_sex)\n",
    "    subject.attrs.set('xnat:subjectData/demographics[@xsi:type=xnat:demographicData]/age', str(user_age))\n",
    "    #subject.attrs.set('xnat:subjectData/demographics[@xsi:type=xnat:demographicData]/height', height)\n",
    "    \n",
    "    model ='SIEMENS MAGNETOM TrioTim syngo MR B17'\n",
    "    site ='Hammersmith Hospital'\n",
    "    fs ='3T'\n",
    "    \n",
    "    experiment.attrs.set('xnat:imageSessionData/scanner',model)\n",
    "    experiment.attrs.set('xnat:imageSessionData/fieldStrength',fs)\n",
    "\n",
    "    # Below for inserting scans\n",
    "    if insert_scans==1:\n",
    "        scan_files=[]\n",
    "        scan_files.append(value['T1_path'])\n",
    "        if value['func_path'] != []:\n",
    "            scan_files.append(value['func_path'])\n",
    "    \n",
    "        # Delete old scans if desired\n",
    "        if delete_previous_scans==1:\n",
    "            allScans=experiment.scans()\n",
    "            for scan in allScans:\n",
    "                print \"deleting scans\"\n",
    "                scan.delete()\n",
    "\n",
    "        for ii in range(len(scan_files)):\n",
    "            if ii==0:\n",
    "                scan_type='T1'\n",
    "                scan_name='T1_01'\n",
    "                slice_size='8 1200'\n",
    "            elif ii==1:\n",
    "                scan_type='func_rest'\n",
    "                scan_name='func_rest_02'\n",
    "                slice_size='3 267'\n",
    "\n",
    "            img_reorient='anonymized_reorient.nii.gz'\n",
    "            #cmd_reorient='fslreorient2std ' + value['T1_path'] + ' ' + img_reorient\n",
    "            cmd_reorient='cp ' + scan_files[ii] + ' ' + img_reorient # Don't reorient since already including dcm2nii orientation\n",
    "            os.system(cmd_reorient)\n",
    "\n",
    "            # Now insert the reoriented image\n",
    "            # experiment.scan('1').resource('NIFTI').file(os.path.basename(scans_filtered[sub])).insert(\n",
    "            experiment.scan(scan_name).resource('NIFTI').file(os.path.basename(img_reorient)).insert(\n",
    "            img_reorient,\n",
    "            content=scan_type,\n",
    "            overwrite=True,\n",
    "            type=scan_type,  # May need to change this to SPGR, MPRAGE, FLAIR etc?\n",
    "            format='NIFTI')\n",
    "\n",
    "            # Create ORIGINAL and SNAPSHOT to view the images in the web browser\n",
    "            img_png='tmp.png'\n",
    "            img_gif='tmp.gif'\n",
    "            img_thumb='tmp_thumb.gif'\n",
    "            cmd_create_slices='slicer ' + img_reorient + ' -S ' + slice_size + ' ' + img_png\n",
    "            cmd_convert_gif='convert ' + img_png + ' ' + img_gif\n",
    "            cmd_convert_thumb='convert ' + img_png + ' -resize 240x240 ' + img_thumb\n",
    "\n",
    "            os.system(cmd_create_slices)\n",
    "            os.system(cmd_convert_gif)\n",
    "            os.system(cmd_convert_thumb)\n",
    "\n",
    "            experiment.scan(scan_name).resource('SNAPSHOTS').file(os.path.basename(img_gif)).insert(\n",
    "            img_gif,\n",
    "            content='ORIGINAL',\n",
    "            overwrite=True,\n",
    "            format='GIF')\n",
    "\n",
    "            experiment.scan(scan_name).resource('SNAPSHOTS').file(os.path.basename(img_thumb)).insert(\n",
    "            img_thumb,\n",
    "            content='THUMBNAIL',\n",
    "            overwrite=True,\n",
    "            format='GIF')\n",
    "                                                    \n",
    "\n",
    "#xnat.select.project('demoProj_1').accessibility()\n",
    "#xnat.select.project('demoProj_1').set_accessibility(accessibility='private')\n",
    "\n",
    "#db.select.project('IXI_TEST').create()\n",
    "print \"ok\"\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
